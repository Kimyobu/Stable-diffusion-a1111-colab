{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimyobu/Stable-diffusion-a1111-colab/blob/main/notebooks/comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Environment Setup\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import drive,output\n",
        "import os\n",
        "def install_req():\n",
        "    %cd $WORKSPACE/custom_nodes\n",
        "    try:\n",
        "        for node in os.listdir():\n",
        "            if os.path.isdir(f'./{node}'):\n",
        "                # installer = './' + node + '/install.py'\n",
        "                # if os.path.exists(installer) and os.path.isfile(installer):\n",
        "                #     !python {installer}\n",
        "                reqfile = f\"./{node}/requirements.txt\"\n",
        "                !pip install -r {reqfile}\n",
        "        output.clear()\n",
        "    except Exception as Error:\n",
        "        print(Error)\n",
        "    print('Install Requirement Success')\n",
        "    %cd $WORKSPACE\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "WORKSPACE = 'ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "%cd ./custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n",
        "%cd $WORKSPACE\n",
        "output.clear()\n",
        "!echo 'SetUP Envoriment Complete'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Downloader\n",
        "#@markdown ##Input Your Download URL and Save Directory\n",
        "\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "import os.path as Path\n",
        "WORKSPACE\n",
        "%cd $WORKSPACE\n",
        "model_url = 'https://civitai.com/api/download/models/130720' #@param {type:\"string\"}\n",
        "model_dir = '/content/drive/MyDrive/Models/checkpoints' #@param {type:\"string\"}\n",
        "model_name = 'GuoFeng4XL' #@param {type:\"string\"}\n",
        "model_type = \"safetensors\" # @param [\"safetensors\", \"pth\"] {allow-input: true}\n",
        "model_name += f'.{model_type}'\n",
        "args = f'-O {Path.join(model_dir,model_name)}' if model_name != '' else f'-P {model_dir}'\n",
        "!mkdir -p {model_dir}\n",
        "!wget -c {args} {model_url}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sccYNh7JjVCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Custom Node\n",
        "WORKSPACE\n",
        "install_all_node_requirements = True #@param {type: \"boolean\"}\n",
        "clone_node_project = 'https://github.com/ssitu/ComfyUI_roop.git' #@param {type:\"string\"}\n",
        "%cd $WORKSPACE/custom_nodes\n",
        "!git clone {clone_node_project}\n",
        "if install_all_node_requirements:\n",
        "    install_req()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3igGHD0wgqqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Recommander Checkpoints By ComfyUI\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkkkkkkkkkkkkk"
      },
      "source": [
        "### Run ComfyUI with localtunnel (Recommended Way)<br>‡∏£‡∏±‡∏ô ComfyUI ‡∏î‡πâ‡∏ß‡∏¢ localtunnel (‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏Å‡∏ï‡∏¥)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "WORKSPACE\n",
        "%cd $WORKSPACE\n",
        "install_req()\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "args = '--preview-method auto --dont-print-server --highvram' #@param {type: \"string\"}\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "!python main.py {args}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gggggggggg"
      },
      "source": [
        "### Run ComfyUI with colab iframe (use only in case the previous way with localtunnel doesn't work)\n",
        "\n",
        "You should see the ui appear in an iframe. If you get a 403 error, it's your firefox settings or an extension that's messing things up.\n",
        "\n",
        "If you want to open it in another window use the link.\n",
        "\n",
        "Note that some UI features like live image previews won't work because the colab iframe blocks websockets.\n",
        "\n",
        "### ‡∏£‡∏±‡∏ô ComfyUI ‡∏î‡πâ‡∏ß‡∏¢‡πÅ‡∏ñ‡∏ö output ‡∏Ç‡∏≠‡∏á colab (‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)\n",
        "\n",
        "‡∏ñ‡πâ‡∏≤ UI ‡∏°‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏µ‡πà ‡πÅ‡∏ñ‡∏ö output ‡∏´‡∏£‡∏∑‡∏≠ ‡∏Ç‡∏∂‡πâ‡∏ô error 403 ‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤ browser\n",
        "\n",
        "‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡πâ‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô ‡∏´‡∏£‡∏∑‡∏≠ extension ‡∏ö‡∏•‡πá‡∏≠‡∏Ñ‡∏°‡∏±‡∏ô\n",
        "\n",
        "‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢ ‡∏ö‡∏≤‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏ä‡πà‡∏ô Live Previews ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ colab iframe blocks webstockets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhhhhhhhhh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "WORKSPACE\n",
        "%cd $WORKSPACE\n",
        "install_req()\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  from google.colab import output\n",
        "  output.serve_kernel_port_as_iframe(port, height=1024)\n",
        "  print(\"to open it in a window you can open this link here:\")\n",
        "  output.serve_kernel_port_as_window(port)\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "args = '--preview-method auto --dont-print-server --highvram' #@param {type: \"string\"}\n",
        "!python main.py {args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##File ExplorerüìÅ\n",
        "!pip install -U imjoy-elfinder\n",
        "import threading\n",
        "from google.colab import output\n",
        "from imjoy_elfinder.app import main\n",
        "output.clear()\n",
        "\n",
        "root_dir = \"/content\"\n",
        "open_in_new_tab = False\n",
        "\n",
        "def start_file_explorer(root_dir=root_dir, port=8765):\n",
        "    try:\n",
        "        main([\"--root-dir=\" + root_dir, \"--port=\" + str(port)])\n",
        "    except Exception as e:\n",
        "        print(\"Error starting file explorer:\", str(e))\n",
        "\n",
        "\n",
        "def open_file_explorer(open_in_new_tab=False, root_dir=root_dir, port=8765):\n",
        "    thread = threading.Thread(target=start_file_explorer, args=[root_dir, port])\n",
        "    thread.start()\n",
        "\n",
        "    if open_in_new_tab:\n",
        "        output.serve_kernel_port_as_window(port)\n",
        "    else:\n",
        "        output.serve_kernel_port_as_iframe(port, height=\"500\")\n",
        "\n",
        "open_file_explorer(open_in_new_tab=open_in_new_tab, root_dir=root_dir, port=8765)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YSLLniwsf3Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "rxJNFwK-AW-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#Docs\n",
        "Args | Value\n",
        "       --- | ---\n",
        "            URL | URL to file or URL to download\n",
        "            Dir | Path of Directory to save file\n",
        "            Name | Name of file to save (rename file)\n",
        "            Type | Type of model (extension of file)\n",
        "\n",
        "---\n",
        "\n",
        "###Downloader:\n",
        "   Args | Value\n",
        "           --- | ---\n",
        "                URL | https://civitai.com/api/download/models/138079\n",
        "                Dir | ./models/checkpoints\n",
        "                Name | ReproductionAnimeSDXL\n",
        "                Type | safetensors\n",
        "\n",
        "   ```\n",
        "  Length: 6938042036 (6.5G)\n",
        "  Saving to: ‚Äò$WORKSPACE/models/checkpoints/ReproductionAnimeSDXL.safetensors‚Äô\n",
        "\n",
        "  models/Reproductio... 100%[===================>]   6.46G  58.4MB/s    in 2m 13s\n",
        "\n",
        "  2023-08-13 03:41:16 (49.6 MB/s) - ‚Äò$WORKSPACE/models/checkpoints/ReproductionAnimeSDXL.safetensors‚Äô saved [6938042036/6938042036]\n",
        "   ```\n",
        "   Args | Value\n",
        "           --- | ---\n",
        "                URL | https://civitai.com/api/download/models/138079\n",
        "                Dir | /content/drive/MyDrive/MyModels/checkpoints\n",
        "                Name | GuoFeng4XL\n",
        "                Type | safetensors\n",
        "\n",
        "   ```\n",
        "  Length: 6938041020 (6.5G)\n",
        "Saving to: ‚Äò/content/drive/MyDrive/MyModels/checkpoints/GuoFeng4XL.safetensors‚Äô\n",
        "\n",
        "/content/drive/MyDr 100%[===================>]   6.46G  14.0MB/s    in 10m 7s  \n",
        "\n",
        "2023-08-13 04:07:32 (10.9 MB/s) - ‚Äò/content/drive/MyDrive/MyModels/checkpoints/GuoFeng4XL.safetensors‚Äô saved [6938041020/6938041020]\n",
        "   ```\n",
        "---\n",
        "\n",
        "###CommandLine Argument:\n",
        "Option | Description\n",
        "---|---\n",
        "        -h, --help | show this help message and exit\n",
        "--listen [IP] | Specify the IP address to listen on (default: 127.0.0.1). If --listen is provided without an argument, it defaults to 0.0.0.0. (listens on all)\n",
        "--port [PORT] | Set the listen port.\n",
        "--enable-cors-header [ORIGIN] | Enable CORS (Cross-Origin Resource Sharing) with optional origin or allow all with default '*'.\n",
        "--extra-model-paths-config [PATH (PATH . . .) ] | Load one or more extra_model_paths.yaml files.\n",
        "--output-directory [OUTPUT_DIRECTORY] | Set the ComfyUI output directory.\n",
        "--auto-launch | Automatically launch ComfyUI in the default browser.\n",
        "--cuda-device [DEVICE_ID] | Set the id of the cuda device this instance will use.\n",
        "--cuda-malloc | Enable cudaMallocAsync (enabled by default for torch 2.0 and up).\n",
        "--disable-cuda-malloc | Disable cudaMallocAsync.\n",
        "--dont-upcast-attention | Disable upcasting of attention. Can boost speed but increase the chances of black images.\n",
        "--force-fp32 | Force fp32 (If this makes your GPU work better please report it).\n",
        "--force-fp16 | Force fp16.\n",
        "--fp16-vae | Run the VAE in fp16, might cause black images.\n",
        "--bf16-vae | Run the VAE in bf16, might lower quality.\n",
        "--directml [DIRECTML_DEVICE] | Use torch-directml.\n",
        "--preview-method [none,auto,latent2rgb,taesd] | Default preview method for sampler nodes.\n",
        "--use-split-cross-attention | Use the split cross attention optimization. Ignored when xformers is used.\n",
        "--use-quad-cross-attention | Use the sub-quadratic cross attention optimization . Ignored when xformers is used.\n",
        "--use-pytorch-cross-attention | Use the new pytorch 2.0 cross attention function.\n",
        "--disable-xformers | Disable xformers.\n",
        "--gpu-only | Store and run everything (text encoders/CLIP models, etc... on the GPU).\n",
        "--highvram | By default models will be unloaded to CPU memory after being used. This option keeps them in GPU memory.\n",
        "--normalvram | Used to force normal vram use if lowvram gets automatically enabled.\n",
        "--lowvram | Split the unet in parts to use less vram.\n",
        "--novram | When lowvram isn't enough.\n",
        "--cpu | To use the CPU for everything (slow).\n",
        "--dont-print-server | Don't print server output.\n",
        "--quick-test-for-ci | Quick test for CI.\n",
        "--windows-standalone-build | Windows standalone build: Enable convenient things that most people using the standalone windows build will probably enjoy (like auto opening the page on startup).\n",
        "--disable-metadata | Disable saving prompt metadata in files.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "brFe7v0dAY48"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}