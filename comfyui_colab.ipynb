{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimyobu/Stable-diffusion-a1111-colab/blob/main/comfyui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "Git clone the repo and install the requirements. (ignore the pip errors about protobuf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbbbbbbbbb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title # <font size='7'> <font color=\"#3d73f2\">**Comfy</font><font color=\"#3db6f2\">U</font>I** <font size=\"6\"> <font color=\"#ff8f4a\">Environment Setup <font color=\"white\">‚¨áÔ∏è/üîÉ\n",
        "%cd /content\n",
        "from pathlib import Path\n",
        "from google.colab import drive,output\n",
        "from IPython.display import display, Markdown, Latex\n",
        "import os\n",
        "def install_req():\n",
        "    %cd $WORKSPACE/custom_nodes\n",
        "    try:\n",
        "        for node in os.listdir():\n",
        "            reqfile = f\"./{node}/requirements.txt\"\n",
        "            if os.path.isfile(reqfile):\n",
        "                !pip install -r {reqfile}\n",
        "        output.clear()\n",
        "    except Exception as Error:\n",
        "        print(Error)\n",
        "    print('Install Requirement Success')\n",
        "    %cd $WORKSPACE\n",
        "\n",
        "def MD(markdownstring):\n",
        "    return display(Markdown(markdownstring))\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = False  #@param {type:\"boolean\"}\n",
        "WORKSPACE = '/content/ComfyUI'\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    if not os.path.isdir('/content/drive'):\n",
        "        !echo \"Mounting Google Drive...\"\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "%cd ./custom_nodes\n",
        "!git clone https://github.com/ltdrdata/ComfyUI-Manager.git\n",
        "%cd $WORKSPACE\n",
        "output.clear()\n",
        "MD('<font color=\"lime\"> SetUP Envoriment Complete‚úì')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cccccccccc"
      },
      "source": [
        "Download some models/checkpoints/vae or custom comfyui nodes (uncomment the commands for the ones you want)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font size=\"6\" color=\"#ff4aff\">**Models**<font color=\"cyan\"> ManagerüåÄ"
      ],
      "metadata": {
        "id": "iaL0-OdE7_hJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color=\"cyan\">Downloader‚¨áÔ∏è\n",
        "#@markdown ##Input Your Download URL and Model Directory\n",
        "\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "import os.path as Path\n",
        "WORKSPACE\n",
        "%cd $WORKSPACE\n",
        "model_url = 'https://civitai.com/api/download/models/104291' #@param {type:\"string\"}\n",
        "model_dir = './models/loras' #@param {type:\"string\"}\n",
        "model_name = 'hanfu-tang_lora' #@param {type:\"string\"}\n",
        "model_type = \"safetensors\" # @param [\"safetensors\", \"pth\"] {allow-input: true}\n",
        "save_name = f'{model_name}.{model_type}'\n",
        "args = f'-O {Path.join(model_dir,save_name)}' if model_name != '' else f'-P {model_dir}'\n",
        "!mkdir -p {model_dir}\n",
        "!wget -c {args} {model_url}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sccYNh7JjVCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NZSWfvOCjNqo"
      },
      "outputs": [],
      "source": [
        "#@title <font color=\"orange\">**Goo<font color=\"#20b000\">gle_<font color=\"#70bcff\">Drive** <font color=\"cyan\">Downloader‚¨áÔ∏è\n",
        "#@markdown ##Input Your Download URL and Save Directory\n",
        "\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "\n",
        "#@markdown * Save Model To Drive\n",
        "import os.path as Path\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive,output\n",
        "WORKSPACE\n",
        "%cd /content\n",
        "if not os.path.isdir('/content/drive'):\n",
        "        !echo \"Mounting Google Drive...\"\n",
        "        drive.mount('/content/drive')\n",
        "%cd $WORKSPACE\n",
        "SAVE_dir = '/content/drive/MyDrive/Save_Data' #@param {type:\"string\"}\n",
        "SAVE_As = 'models.json' #@param [\"models.json\"]\n",
        "check_list = False #@param {type:\"boolean\"}\n",
        "uninstall_model = False #@param {type:\"boolean\"}\n",
        "uninstall_dir = False #@param {type:\"boolean\"}\n",
        "import_to_workspcae = True #@param {type:\"boolean\"}\n",
        "model_url = 'https://civitai.com/api/download/models/104291' #@param {type:\"string\"}\n",
        "model_dir = './models/loras' #@param {type:\"string\"}\n",
        "model_name = 'hanfu-tang_lora' #@param {type:\"string\"}\n",
        "model_type = \"safetensors\" # @param [\"safetensors\", \"pth\"] {allow-input: true}\n",
        "save_name = f'{model_name}.{model_type}'\n",
        "args = f'-O {Path.join(model_dir,save_name)}' if model_name != '' else f'-P {model_dir}'\n",
        "\n",
        "!mkdir -p {SAVE_dir}\n",
        "JSON = Path.join(SAVE_dir,SAVE_As)\n",
        "\n",
        "if not Path.isfile(JSON):\n",
        "    !echo -= Creating DataBase File =-\n",
        "    !echo '{}' > $JSON\n",
        "\n",
        "r = open(JSON,'r')\n",
        "Models = json.loads(r.read())\n",
        "r.close()\n",
        "\n",
        "def check():\n",
        "    print(f'\\nCurrent List:\\n{json.dumps(Models,indent=2)}\\n')\n",
        "\n",
        "def update():\n",
        "    r = open(JSON,'w')\n",
        "    r.write(json.dumps(Models,indent=2))\n",
        "    r.close()\n",
        "\n",
        "print('\\n')\n",
        "msg = save_name if model_name != '' else model_url\n",
        "if check_list:\n",
        "    output.clear()\n",
        "    check()\n",
        "elif uninstall_dir:\n",
        "    if model_dir in Models:\n",
        "        Models.pop(model_dir)\n",
        "        print(f'Remove Directory {model_dir}')\n",
        "        check()\n",
        "elif uninstall_model:\n",
        "    if model_dir in Models:\n",
        "        m = Models[model_dir]\n",
        "        target = [x for x in m if x['url']==model_url or x['name']==model_name]\n",
        "        if len(target) != 0:\n",
        "            for x in target:\n",
        "                m.remove(x)\n",
        "                n = x['name']\n",
        "                u = x['url']\n",
        "                print(f'Remove {n}/{u} in {model_dir}')\n",
        "            print(f'Remove All match {msg}/{model_url} from {model_dir}')\n",
        "        else:\n",
        "            print(f'No match {msg}/{model_url} in List')\n",
        "        Models[model_dir] = m\n",
        "        if len(m) == 0:\n",
        "            Models.pop(model_dir)\n",
        "            print(f'Remove Empty Directory {model_dir}')\n",
        "        check()\n",
        "    else:\n",
        "        print(f'{model_dir} is Empty')\n",
        "else:\n",
        "    if not isinstance(Models.get(model_dir),list):\n",
        "        Models.setdefault(model_dir,[])\n",
        "    data = {'url':model_url,'name':model_name,'type':model_type}\n",
        "    if data in Models[model_dir]:\n",
        "        print('\\nThe file is already fully retrieved; nothing to do.\\n')\n",
        "    else:\n",
        "        Models[model_dir].append(data)\n",
        "        print(f'\\nAdd {msg} in {model_dir}\\n')\n",
        "    if import_to_workspcae:\n",
        "        print('Wait for Import File to Workspcae\\n')\n",
        "        !wget -c {model_url} {args}\n",
        "\n",
        "update()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import All Saved Model From Google_Drive‚¨áÔ∏èüíæ\n",
        "import os\n",
        "import os.path as Path\n",
        "from google.colab import drive\n",
        "WORKSPACE\n",
        "%cd /content\n",
        "if not os.path.isdir('/content/drive'):\n",
        "        !echo \"Mounting Google Drive...\"\n",
        "        drive.mount('/content/drive')\n",
        "%cd $WORKSPACE\n",
        "SAVE_dir = '/content/drive/MyDrive/Save_Data' #@param {type:\"string\"}\n",
        "OPEN_As = 'models.json' #@param [\"models.json\"]\n",
        "File_Path = Path.join(SAVE_dir,OPEN_As)\n",
        "if not Path.isdir(SAVE_dir):\n",
        "    print(f'Path: {SAVE_dir} is not directory!!')\n",
        "elif not Path.isfile(File_Path):\n",
        "    print(f'File: {OPEN_As} not found ({File_Path})')\n",
        "\n",
        "r = open(JSON,'r')\n",
        "Models = json.loads(r.read())\n",
        "r.close()\n",
        "\n",
        "def check():\n",
        "    print(f'\\nCurrent List:\\n{json.dumps(Models,indent=2)}\\n')\n",
        "\n",
        "check()\n",
        "for x in Models:\n",
        "    !echo -= Import $x =-\n",
        "    model_dir = x\n",
        "    for m in Models[x]:\n",
        "        model_name = m['name']\n",
        "        model_type = m['type']\n",
        "        model_url = m['url']\n",
        "        save_name = f'{model_name}.{model_type}'\n",
        "        args = f'-O {Path.join(model_dir,save_name)}' if model_name != '' else f'-P {model_dir}'\n",
        "        !mkdir -p {model_dir}\n",
        "        !wget -c {model_url} {args}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ET2Wl607DrR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dddddddddd",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Recommander Checkpoints By ComfyUI‚¨á\n",
        "\n",
        "### SDXL\n",
        "### I recommend these workflow examples: https://comfyanonymous.github.io/ComfyUI_examples/sdxl/\n",
        "\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# SD1.5\n",
        "!wget -c https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P ./models/checkpoints/\n",
        "\n",
        "# SD2\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1-base/resolve/main/v2-1_512-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Some SD1.5 anime style\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix2/AbyssOrangeMix2_hard.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A1_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/Models/AbyssOrangeMix3/AOM3A3_orangemixs.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/anything-v3-fp16-pruned.safetensors -P ./models/checkpoints/\n",
        "\n",
        "# Waifu Diffusion 1.5 (anime style SD2.x 768-v)\n",
        "#!wget -c https://huggingface.co/waifu-diffusion/wd-1-5-beta3/resolve/main/wd-illusion-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# unCLIP models\n",
        "#!wget -c https://huggingface.co/comfyanonymous/illuminatiDiffusionV1_v11_unCLIP/resolve/main/illuminatiDiffusionV1_v11-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/wd-1.5-beta2_unCLIP/resolve/main/wd-1-5-beta2-aesthetic-unclip-h-fp16.safetensors -P ./models/checkpoints/\n",
        "\n",
        "\n",
        "# VAE\n",
        "!wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/WarriorMama777/OrangeMixs/resolve/main/VAEs/orangemix.vae.pt -P ./models/vae/\n",
        "#!wget -c https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/vae/kl-f8-anime2.ckpt -P ./models/vae/\n",
        "\n",
        "\n",
        "# Loras\n",
        "#!wget -c https://civitai.com/api/download/models/10350 -O ./models/loras/theovercomer8sContrastFix_sd21768.safetensors #theovercomer8sContrastFix SD2.x 768-v\n",
        "#!wget -c https://civitai.com/api/download/models/10638 -O ./models/loras/theovercomer8sContrastFix_sd15.safetensors #theovercomer8sContrastFix SD1.x\n",
        "#!wget -c https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors -P ./models/loras/ #SDXL offset noise lora\n",
        "\n",
        "\n",
        "# T2I-Adapter\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_depth_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_seg_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_sketch_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_keypose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_openpose_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_color_sd14v1.pth -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_canny_sd14v1.pth -P ./models/controlnet/\n",
        "\n",
        "# T2I Styles Model\n",
        "#!wget -c https://huggingface.co/TencentARC/T2I-Adapter/resolve/main/models/t2iadapter_style_sd14v1.pth -P ./models/style_models/\n",
        "\n",
        "# CLIPVision model (needed for styles model)\n",
        "#!wget -c https://huggingface.co/openai/clip-vit-large-patch14/resolve/main/pytorch_model.bin -O ./models/clip_vision/clip_vit14.bin\n",
        "\n",
        "\n",
        "# ControlNet\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_ip2p_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11e_sd15_shuffle_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_canny_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11f1p_sd15_depth_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_inpaint_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_lineart_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_mlsd_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_normalbae_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_openpose_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_scribble_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_seg_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15_softedge_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11p_sd15s2_lineart_anime_fp16.safetensors -P ./models/controlnet/\n",
        "#!wget -c https://huggingface.co/comfyanonymous/ControlNet-v1-1_fp16_safetensors/resolve/main/control_v11u_sd15_tile_fp16.safetensors -P ./models/controlnet/\n",
        "\n",
        "\n",
        "# Controlnet Preprocessor nodes by Fannovel16\n",
        "#!cd custom_nodes && git clone https://github.com/Fannovel16/comfy_controlnet_preprocessors; cd comfy_controlnet_preprocessors && python install.py\n",
        "\n",
        "\n",
        "# GLIGEN\n",
        "#!wget -c https://huggingface.co/comfyanonymous/GLIGEN_pruned_safetensors/resolve/main/gligen_sd14_textbox_pruned_fp16.safetensors -P ./models/gligen/\n",
        "\n",
        "\n",
        "# ESRGAN upscale model\n",
        "#!wget -c https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x2.pth -P ./models/upscale_models/\n",
        "#!wget -c https://huggingface.co/sberbank-ai/Real-ESRGAN/resolve/main/RealESRGAN_x4.pth -P ./models/upscale_models/"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**<font color=\"white\" size=\"6\">Custom Node ‚öôÔ∏è**"
      ],
      "metadata": {
        "id": "Rc-rnYjB3V3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color=\"yellow\" size=\"5\"> Install Custom Node‚¨áÔ∏è\n",
        "WORKSPACE\n",
        "install_all_node_requirements = False #@param {type: \"boolean\"}\n",
        "clone_node_project = 'https://github.com/gamert/ComfyUI_tagger.git' #@param {type:\"string\"}\n",
        "%cd $WORKSPACE/custom_nodes\n",
        "!git clone {clone_node_project}\n",
        "import os.path as Path\n",
        "repo = f'./{Path.basename(os.path.splitext(clone_node_project)[0])}'\n",
        "reqfile = f'{repo}/requirements.txt'\n",
        "if Path.isfile(reqfile):\n",
        "    !pip install -r {reqfile}\n",
        "else:\n",
        "    print('Requirements file not found')\n",
        "if install_all_node_requirements:\n",
        "    install_req()"
      ],
      "metadata": {
        "id": "3igGHD0wgqqr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font color=\"lime\" size=\"5\"> Update Custome Node üîÉ\n",
        "import os\n",
        "WORKSPACE\n",
        "p = f'{WORKSPACE}/custom_nodes'\n",
        "%cd $p\n",
        "Update_All_Nodes = True #@param {type: \"boolean\"}\n",
        "Force_Pull = False #@param {type: \"boolean\"}\n",
        "#@markdown <font color=\"red\" size=\"4\">Force Pull Will Overwrite all file !!<br>Force Pull ‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏ó‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î !!</font>\n",
        "Node_folder = './ComfyUI-Manager' #@param {type: \"string\"}\n",
        "if Update_All_Nodes:\n",
        "    for x in os.listdir():\n",
        "        x = os.path.join(p,x)\n",
        "        if os.path.isdir(x):\n",
        "            %cd {x}\n",
        "            !git pull\n",
        "else :\n",
        "    %cd $Node_folder\n",
        "    !git fetch --all\n",
        "    !git reset --hard origin\n",
        "    !git pull"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SG__Tran3jNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**<font size=\"7\" color=\"orange\">Launch <font color=\"#3d73f2\">Web<font color=\"#3db6f2\">U<font color=\"white\">I üöÄ**"
      ],
      "metadata": {
        "id": "i7TpNnasshNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <font size=\"5\" color=\"lime\">Run <font color=\"#3d73f2\">**Comfy</font><font color=\"#3db6f2\">U<font color=\"white\">I** <font color=\"pink\">with <font color=\"orange\">cloudflared\n",
        "# @markdown ### Run ComfyUI with cloudflared (Recommended Way)<br>‡∏£‡∏±‡∏ô ComfyUI ‡∏î‡πâ‡∏ß‡∏¢ cloudflared (‡∏ß‡∏¥‡∏ò‡∏µ‡∏õ‡∏Å‡∏ï‡∏¥)\n",
        "WORKSPACE\n",
        "%cd /content\n",
        "!wget -c https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "install_all_node_requirements = True #@param {type: \"boolean\"}\n",
        "if install_all_node_requirements:\n",
        "    install_req()\n",
        "%cd $WORKSPACE\n",
        "from google.colab import output\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "output.clear()\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--loglevel\", \"info\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "args = '--preview-method auto --dont-print-server --highvram' #@param {type: \"string\"}\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "!python main.py {args}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oFdEklm9rIcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <font size=\"5\" color=\"lime\">Run <font color=\"#3d73f2\">**Comfy</font><font color=\"#3db6f2\">U<font color=\"white\">I** <font color=\"pink\">with <font color=\"red\">Local<font color=\"white\">tunnel\n",
        "# @markdown ### Run ComfyUI with localtunnel (Optional)<br>‡∏£‡∏±‡∏ô ComfyUI ‡∏î‡πâ‡∏ß‡∏¢ localtunnel (‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ)\n",
        "WORKSPACE\n",
        "%cd $WORKSPACE\n",
        "install_all_node_requirements = True #@param {type: \"boolean\"}\n",
        "if install_all_node_requirements:\n",
        "    install_req()\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "args = '--preview-method auto --dont-print-server --highvram' #@param {type: \"string\"}\n",
        "#@markdown See <a href='#scrollTo=brFe7v0dAY48'>Docs</a>.\n",
        "!python main.py {args}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ##<font color=\"yellow\">File ExplorerüìÅ\n",
        "!pip install -U imjoy-elfinder\n",
        "import threading\n",
        "from google.colab import output\n",
        "from imjoy_elfinder.app import main\n",
        "output.clear()\n",
        "\n",
        "PORT = 4321 #@param {type:\"number\"}\n",
        "root_dir = \"/content\"\n",
        "open_in_new_tab = False\n",
        "\n",
        "def start_file_explorer(root_dir=root_dir, port=PORT):\n",
        "    try:\n",
        "        main([\"--root-dir=\" + root_dir, \"--port=\" + str(port)])\n",
        "    except Exception as e:\n",
        "        print(\"Error starting file explorer:\", str(e))\n",
        "\n",
        "\n",
        "def open_file_explorer(open_in_new_tab=False, root_dir=root_dir, port=PORT):\n",
        "    thread = threading.Thread(target=start_file_explorer, args=[root_dir, port])\n",
        "    thread.start()\n",
        "    output.serve_kernel_port_as_iframe(port, height=\"500\")\n",
        "\n",
        "open_file_explorer(port=PORT)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YSLLniwsf3Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#Docs\n",
        "Args | Value\n",
        "       --- | ---\n",
        "            URL | URL to file or URL to download\n",
        "            Dir | Path of Directory to save file\n",
        "            Name | Name of file to save (rename file)\n",
        "            Type | Type of model (extension of file)\n",
        "\n",
        "---\n",
        "\n",
        "###Downloader:\n",
        "   Args | Value\n",
        "           --- | ---\n",
        "                URL | https://civitai.com/api/download/models/138079\n",
        "                Dir | ./models/checkpoints\n",
        "                Name | ReproductionAnimeSDXL\n",
        "                Type | safetensors\n",
        "\n",
        "   ```\n",
        "  Length: 6938042036 (6.5G)\n",
        "  Saving to: ‚Äò$WORKSPACE/models/checkpoints/ReproductionAnimeSDXL.safetensors‚Äô\n",
        "\n",
        "  models/Reproductio... 100%[===================>]   6.46G  58.4MB/s    in 2m 13s\n",
        "\n",
        "  2023-08-13 03:41:16 (49.6 MB/s) - ‚Äò$WORKSPACE/models/checkpoints/ReproductionAnimeSDXL.safetensors‚Äô saved [6938042036/6938042036]\n",
        "   ```\n",
        "   Args | Value\n",
        "           --- | ---\n",
        "                URL | https://civitai.com/api/download/models/138079\n",
        "                Dir | /content/drive/MyDrive/MyModels/checkpoints\n",
        "                Name | GuoFeng4XL\n",
        "                Type | safetensors\n",
        "\n",
        "   ```\n",
        "  Length: 6938041020 (6.5G)\n",
        "Saving to: ‚Äò/content/drive/MyDrive/MyModels/checkpoints/GuoFeng4XL.safetensors‚Äô\n",
        "\n",
        "/content/drive/MyDr 100%[===================>]   6.46G  14.0MB/s    in 10m 7s  \n",
        "\n",
        "2023-08-13 04:07:32 (10.9 MB/s) - ‚Äò/content/drive/MyDrive/MyModels/checkpoints/GuoFeng4XL.safetensors‚Äô saved [6938041020/6938041020]\n",
        "   ```\n",
        "---\n",
        "\n",
        "###CommandLine Argument:\n",
        "Option | Description\n",
        "---|---\n",
        "        -h, --help | show this help message and exit\n",
        "--listen [IP] | Specify the IP address to listen on (default: 127.0.0.1). If --listen is provided without an argument, it defaults to 0.0.0.0. (listens on all)\n",
        "--port [PORT] | Set the listen port.\n",
        "--enable-cors-header [ORIGIN] | Enable CORS (Cross-Origin Resource Sharing) with optional origin or allow all with default '*'.\n",
        "--extra-model-paths-config [PATH (PATH . . .) ] | Load one or more extra_model_paths.yaml files.\n",
        "--output-directory [OUTPUT_DIRECTORY] | Set the ComfyUI output directory.\n",
        "--auto-launch | Automatically launch ComfyUI in the default browser.\n",
        "--cuda-device [DEVICE_ID] | Set the id of the cuda device this instance will use.\n",
        "--cuda-malloc | Enable cudaMallocAsync (enabled by default for torch 2.0 and up).\n",
        "--disable-cuda-malloc | Disable cudaMallocAsync.\n",
        "--dont-upcast-attention | Disable upcasting of attention. Can boost speed but increase the chances of black images.\n",
        "--force-fp32 | Force fp32 (If this makes your GPU work better please report it).\n",
        "--force-fp16 | Force fp16.\n",
        "--fp16-vae | Run the VAE in fp16, might cause black images.\n",
        "--bf16-vae | Run the VAE in bf16, might lower quality.\n",
        "--directml [DIRECTML_DEVICE] | Use torch-directml.\n",
        "--preview-method [none,auto,latent2rgb,taesd] | Default preview method for sampler nodes.\n",
        "--use-split-cross-attention | Use the split cross attention optimization. Ignored when xformers is used.\n",
        "--use-quad-cross-attention | Use the sub-quadratic cross attention optimization . Ignored when xformers is used.\n",
        "--use-pytorch-cross-attention | Use the new pytorch 2.0 cross attention function.\n",
        "--disable-xformers | Disable xformers.\n",
        "--gpu-only | Store and run everything (text encoders/CLIP models, etc... on the GPU).\n",
        "--highvram | By default models will be unloaded to CPU memory after being used. This option keeps them in GPU memory.\n",
        "--normalvram | Used to force normal vram use if lowvram gets automatically enabled.\n",
        "--lowvram | Split the unet in parts to use less vram.\n",
        "--novram | When lowvram isn't enough.\n",
        "--cpu | To use the CPU for everything (slow).\n",
        "--dont-print-server | Don't print server output.\n",
        "--quick-test-for-ci | Quick test for CI.\n",
        "--windows-standalone-build | Windows standalone build: Enable convenient things that most people using the standalone windows build will probably enjoy (like auto opening the page on startup).\n",
        "--disable-metadata | Disable saving prompt metadata in files.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "brFe7v0dAY48"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}